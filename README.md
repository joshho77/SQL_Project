# Josh Ho - SQL Project | Transforming and Analyzing Data with PostgreSQL

## Project Goals
1. Efficiently and concisely clean and transform raw data for loading into a Postgres database

2. Use proficient DDL and DML to create logical tables to house and work with the cleaned data
3. Build and implement advanced SQL queries to develop meaningful insights from the given data
4. Implement a QA process to validate transformed data
5. Load the relevant findings and documentation into a GitHub repository for version control
***
## Process
Step 1. Clean and transform acquired data to prep for loading into a SQL editor

Step 2. Load transformed data into editor by creating tables and copying the data that is in a .csv format

Step 3. Develop queries to answer the questions provided, as well as my own.

Step 4. Validate transformed data using a quality analysis process

Step 5. Create an ERD using the SQL editor to define entity/attribute relationships

Step 6. Document all data within the appropriate markdown files and push to Github repo

Step 7. Complete!
***
## Results
Discovered that the data relates to an ecommerce business, storing information regarding revenue, web traffic, customer analytics, and inventory.

With the data given I was able to answer a variety of different business questions surrounding the logistics and patterns of the business. Additionally, I was able to analyze the data using my own questions in order to find relevant business data and information.

All these results are stored within the files associated with this project.
***
## Challenges 
One challenge was trying to understand and clean the data, while simultaneously determining which columns were actually relevant to answering the project questions. Mainly because many of the column names were not descriptive based on the data points they were trying to capture.

Another challenge was trying to interpret the intention and underlying goal of the questions provided, as they sometimes felt vague or unclear in what they were trying to uncover within the data.
***
## Future Goals
If given more time, I would attempt to work with the originator of this data and try to build a relevant and descriptive schema for all the tables. Trying to figure out what each column name truly means and the meaning behind the data it is tracking. Ultimately, to create accurate and useful definitions for each attribute, and effectively outline the cardinality between the entities, further allowing me to grasp the data in a more complete sense.
